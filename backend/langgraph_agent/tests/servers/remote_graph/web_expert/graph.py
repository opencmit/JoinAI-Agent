"""
Webç½‘é¡µå¼€å‘ä¸“å®¶æ™ºèƒ½ä½“æœåŠ¡ - ä¸¤èŠ‚ç‚¹æ¶æ„ï¼ˆplanner + agentï¼‰
"""

import os
import sys
from typing import Annotated, Iterator
from typing_extensions import TypedDict

from langchain_core.messages import BaseMessage,SystemMessage, HumanMessage, AIMessage, ToolMessage
from langchain.chat_models import init_chat_model
from langgraph.graph import StateGraph, START, END
from langgraph.graph.message import add_messages

# æ·»åŠ toolsç›®å½•åˆ°Pythonè·¯å¾„
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..'))
from tools.base_tools import get_current_time, search_web, read_file, write_file, word_count
from tools.web_tools import generate_html_preview, validate_css, check_responsive


class State(TypedDict):
    """å›¾çŠ¶æ€å®šä¹‰"""
    messages: Annotated[list, add_messages]


def create_web_planner():
    """åˆ›å»ºWebå¼€å‘è§„åˆ’èŠ‚ç‚¹"""
    
    # ä»ç¯å¢ƒå˜é‡è·å–æ¨¡å‹é…ç½®
    model_name = os.getenv("OPENAI_MODEL", "gpt-4")
    base_url = os.getenv("OPENAI_BASE_URL")
    api_key = os.getenv("OPENAI_API_KEY")
    
    if not api_key:
        raise ValueError("OPENAI_API_KEYç¯å¢ƒå˜é‡æœªè®¾ç½®")
    
    # åˆå§‹åŒ–èŠå¤©æ¨¡å‹
    model_config = {"api_key": api_key}
    if base_url:
        model_config["base_url"] = base_url
        
    llm = init_chat_model(f"openai:{model_name}", **model_config)
    
    # Webå¼€å‘è§„åˆ’ç³»ç»Ÿæç¤ºè¯
    planner_prompt = """ä½ æ˜¯Webå¼€å‘è§„åˆ’åŠ©æ‰‹ï¼Œè´Ÿè´£åˆ†æéœ€æ±‚å¹¶è®¾è®¡æŠ€æœ¯æ–¹æ¡ˆã€‚

ã€è§„åˆ’ä»»åŠ¡ã€‘
1. åˆ†æç”¨æˆ·çš„Webå¼€å‘éœ€æ±‚
2. é€‰æ‹©åˆé€‚çš„æŠ€æœ¯æ ˆå’Œæ¡†æ¶
3. è®¾è®¡ç»„ä»¶ç»“æ„å’Œæ¶æ„
4. è§„åˆ’å®ç°æ­¥éª¤å’Œä¼˜å…ˆçº§
5. åˆ¶å®šæ€§èƒ½å’Œä½“éªŒä¼˜åŒ–ç­–ç•¥

ã€è¾“å‡ºæ ¼å¼ã€‘
ğŸ“‹ Webå¼€å‘è§„åˆ’æ–¹æ¡ˆï¼š

ã€éœ€æ±‚åˆ†æã€‘
- åŠŸèƒ½éœ€æ±‚ï¼š[æ ¸å¿ƒåŠŸèƒ½åˆ—è¡¨]
- ç”¨æˆ·ä½“éªŒï¼š[äº¤äº’å’Œè§†è§‰è¦æ±‚]

ã€æŠ€æœ¯é€‰å‹ã€‘
- å‰ç«¯æ¡†æ¶ï¼š[React/Vue/Angularç­‰]
- æ ·å¼æ–¹æ¡ˆï¼š[CSSæ¡†æ¶/é¢„å¤„ç†å™¨]
- æ„å»ºå·¥å…·ï¼š[Webpack/Viteç­‰]
- å…¶ä»–å·¥å…·ï¼š[çŠ¶æ€ç®¡ç†/è·¯ç”±ç­‰]

ã€æ¶æ„è®¾è®¡ã€‘
- ç›®å½•ç»“æ„ï¼š[é¡¹ç›®ç»„ç»‡æ–¹å¼]
- ç»„ä»¶åˆ’åˆ†ï¼š[ç»„ä»¶å±‚æ¬¡å’ŒèŒè´£]
- æ•°æ®æµå‘ï¼š[çŠ¶æ€ç®¡ç†æ–¹æ¡ˆ]

ã€å®ç°æ­¥éª¤ã€‘
1. åŸºç¡€æ­å»ºï¼š[ç¯å¢ƒé…ç½®]
2. æ ¸å¿ƒåŠŸèƒ½ï¼š[ä¸»è¦æ¨¡å—]
3. ä¼˜åŒ–å®Œå–„ï¼š[æ€§èƒ½/ä½“éªŒ]

ã€ä¼˜åŒ–è¦ç‚¹ã€‘
- æ€§èƒ½ä¼˜åŒ–ï¼š[åŠ è½½/æ¸²æŸ“ä¼˜åŒ–]
- å“åº”å¼è®¾è®¡ï¼š[å¤šè®¾å¤‡é€‚é…]
- æ— éšœç¢æ€§ï¼š[å¯è®¿é—®æ€§è€ƒè™‘]"""

    def planner_node(state: State) -> Iterator[dict]:
        """Webè§„åˆ’èŠ‚ç‚¹ - åŒæ­¥æµå¼è¾“å‡º"""
        messages = state["messages"]
        
        # æ„å»ºè§„åˆ’æ¶ˆæ¯
        planning_messages = [SystemMessage(content=planner_prompt)]
        
        # æ·»åŠ ç”¨æˆ·æ¶ˆæ¯
        if messages:
            planning_messages.extend(messages)
        
        # ä½¿ç”¨ stream è¿›è¡ŒåŒæ­¥æµå¼è°ƒç”¨ï¼Œç´¯ç§¯å†…å®¹
        accumulated_content = ""
        for chunk in llm.stream(planning_messages):
            # å¤„ç†æµå¼è¾“å‡ºçš„æ¯ä¸ªå—
            if hasattr(chunk, 'content') and chunk.content:
                accumulated_content += chunk.content
                # åªè¿”å›LLMç”Ÿæˆçš„å†…å®¹
                yield {"messages": [AIMessage(content=accumulated_content)]}
        
        # å¦‚æœæ²¡æœ‰å†…å®¹ç”Ÿæˆï¼Œè¿”å›ç©ºæ¶ˆæ¯
        if not accumulated_content:
            yield {"messages": [AIMessage(content="")]}
    
    return planner_node


def create_web_agent():
    """åˆ›å»ºWebå¼€å‘æ‰§è¡ŒèŠ‚ç‚¹"""
    
    # ä»ç¯å¢ƒå˜é‡è·å–æ¨¡å‹é…ç½®
    model_name = os.getenv("OPENAI_MODEL", "gpt-4")
    base_url = os.getenv("OPENAI_BASE_URL")
    api_key = os.getenv("OPENAI_API_KEY")
    
    if not api_key:
        raise ValueError("OPENAI_API_KEYç¯å¢ƒå˜é‡æœªè®¾ç½®")
    
    # åˆå§‹åŒ–èŠå¤©æ¨¡å‹
    model_config = {"api_key": api_key}
    if base_url:
        model_config["base_url"] = base_url
        
    llm = init_chat_model(f"openai:{model_name}", **model_config)
    
    # ç»‘å®šå·¥å…·åˆ°LLM
    tools = [
        get_current_time,
        search_web,
        read_file,
        write_file,
        word_count,
        generate_html_preview,
        validate_css,
        check_responsive
    ]
    llm_with_tools = llm.bind_tools(tools)
    
    # Webå¼€å‘æ‰§è¡Œç³»ç»Ÿæç¤ºè¯
    system_prompt = """ä½ æ˜¯ä¸€ä½èµ„æ·±çš„Webå¼€å‘ä¸“å®¶ï¼Œæ ¹æ®å‰é¢çš„è§„åˆ’æ–¹æ¡ˆå®ç°Webå¼€å‘ä»»åŠ¡ã€‚

ã€æ ¸å¿ƒæŠ€æœ¯æ ˆã€‘
ğŸ”§ å‰ç«¯å¼€å‘
â€¢ HTML5/CSS3ï¼šè¯­ä¹‰åŒ–æ ‡ç­¾ã€ç°ä»£å¸ƒå±€ï¼ˆFlexbox/Gridï¼‰
â€¢ JavaScript/ES6+ï¼šåŸç”ŸJSã€å¼‚æ­¥ç¼–ç¨‹ã€æ¨¡å—åŒ–
â€¢ TypeScriptï¼šç±»å‹å®‰å…¨ã€æ¥å£è®¾è®¡ã€æ³›å‹åº”ç”¨

ğŸ“š æ¡†æ¶ç”Ÿæ€
â€¢ React.jsï¼šç»„ä»¶åŒ–å¼€å‘ã€Hooksã€çŠ¶æ€ç®¡ç†
â€¢ Vue.jsï¼šå“åº”å¼æ•°æ®ã€ç»„åˆå¼APIã€ç”Ÿæ€å·¥å…·
â€¢ Angularï¼šä¼ä¸šçº§åº”ç”¨ã€ä¾èµ–æ³¨å…¥ã€RxJS
â€¢ Next.js/Nuxt.jsï¼šå…¨æ ˆæ¡†æ¶ã€SSR/SSG

ğŸ¨ æ ·å¼ä¸è®¾è®¡
â€¢ CSSé¢„å¤„ç†å™¨ï¼šSass/Less/Stylus
â€¢ UIæ¡†æ¶ï¼šTailwind CSSã€Material-UIã€Ant Design
â€¢ å“åº”å¼è®¾è®¡ï¼šç§»åŠ¨ä¼˜å…ˆã€æ–­ç‚¹ç®¡ç†
â€¢ åŠ¨ç”»æ•ˆæœï¼šCSS Animationã€Framer Motion

ã€å¯ç”¨å·¥å…·ã€‘
ä½ å¯ä»¥ä½¿ç”¨ä»¥ä¸‹å·¥å…·æ¥è¾…åŠ©Webå¼€å‘ï¼š
- get_current_time: è·å–å½“å‰æ—¶é—´
- search_web: æœç´¢ç½‘ç»œè·å–å‚è€ƒä¿¡æ¯
- read_file/write_file: è¯»å–æˆ–ä¿å­˜æ–‡æ¡£
- word_count: ç»Ÿè®¡å­—æ•°
- generate_html_preview: ç”ŸæˆHTMLé¢„è§ˆ
- validate_css: éªŒè¯CSSä»£ç 
- check_responsive: æ£€æŸ¥å“åº”å¼è®¾è®¡

ã€æ‰§è¡Œè¦æ±‚ã€‘
åŸºäºå‰é¢çš„è§„åˆ’æ–¹æ¡ˆï¼Œæä¾›å®Œæ•´çš„ä»£ç å®ç°ï¼š
â€¢ éµå¾ªè§„åˆ’çš„æŠ€æœ¯é€‰å‹å’Œæ¶æ„è®¾è®¡
â€¢ å®ç°è§„åˆ’ä¸­çš„åŠŸèƒ½éœ€æ±‚
â€¢ åŒ…å«è¯¦ç»†çš„ä»£ç æ³¨é‡Š
â€¢ ç¡®ä¿ä»£ç çš„å¯ç»´æŠ¤æ€§å’Œæ‰©å±•æ€§
â€¢ è€ƒè™‘æµè§ˆå™¨å…¼å®¹æ€§å’Œæ€§èƒ½ä¼˜åŒ–

è¾“å‡ºå®Œæ•´ã€å¯è¿è¡Œçš„HTML/CSS/JavaScriptä»£ç ã€‚"""

    def agent_node(state: State) -> Iterator[dict]:
        """Webå¼€å‘æ‰§è¡ŒèŠ‚ç‚¹ - åŒæ­¥æµå¼è¾“å‡º"""
        messages = state["messages"]
        
        # æ„å»ºæ‰§è¡Œæ¶ˆæ¯ï¼ˆåŒ…å«è§„åˆ’ä¿¡æ¯ï¼‰
        execution_messages = [SystemMessage(content=system_prompt)]
        
        # æ·»åŠ æ‰€æœ‰å†å²æ¶ˆæ¯ï¼ˆåŒ…æ‹¬è§„åˆ’ï¼‰
        if messages:
            execution_messages.extend(messages)
        
        # ç¬¬ä¸€æ¬¡è°ƒç”¨ - è·å–å·¥å…·è°ƒç”¨å†³å®šï¼ˆéæµå¼ï¼Œå› ä¸ºå·¥å…·è°ƒç”¨éœ€è¦å®Œæ•´å“åº”ï¼‰
        response = llm_with_tools.invoke(execution_messages)
        
        # åˆå§‹åŒ–ç»“æœæ¶ˆæ¯åˆ—è¡¨
        result_messages = []
        
        # å¤„ç†å·¥å…·è°ƒç”¨ï¼ˆå¦‚æœæœ‰ï¼‰
        if hasattr(response, 'tool_calls') and response.tool_calls:
            # ä¿å­˜å¸¦æœ‰å·¥å…·è°ƒç”¨çš„ AIMessage
            result_messages.append(response)
            
            # æ‰§è¡Œå·¥å…·å¹¶åˆ›å»º ToolMessage
            for tool_call in response.tool_calls:
                tool_name = tool_call['name']
                tool_args = tool_call['args']
                tool_id = tool_call.get('id', f"call_{tool_name}")
                
                # æŸ¥æ‰¾å¹¶æ‰§è¡Œå¯¹åº”çš„å·¥å…·
                tool_func = None
                for tool in tools:
                    if tool.name == tool_name:
                        tool_func = tool
                        break
                
                if tool_func:
                    try:
                        # æ‰§è¡Œå·¥å…·
                        tool_result = tool_func.invoke(tool_args)
                        # åˆ›å»º ToolMessage
                        tool_message = ToolMessage(
                            content=str(tool_result),
                            tool_call_id=tool_id
                        )
                        result_messages.append(tool_message)
                    except Exception as e:
                        # é”™è¯¯ä¹Ÿéœ€è¦è¿”å› ToolMessage
                        tool_message = ToolMessage(
                            content=f"å·¥å…·æ‰§è¡Œé”™è¯¯: {str(e)}",
                            tool_call_id=tool_id
                        )
                        result_messages.append(tool_message)
            
            # ç¬¬äºŒæ¬¡è°ƒç”¨ - åŸºäºå·¥å…·ç»“æœç”Ÿæˆæœ€ç»ˆå“åº”
            final_messages = execution_messages + result_messages
            final_response = llm.invoke(final_messages)
            result_messages.append(final_response)
            
            # è¿”å›å®Œæ•´çš„æ¶ˆæ¯é“¾ï¼ˆæµå¼æ¨¡æ‹Ÿï¼Œä½†ä¿ç•™å®Œæ•´æ¶ˆæ¯ï¼‰
            yield {"messages": result_messages}
        else:
            # æ²¡æœ‰å·¥å…·è°ƒç”¨ï¼Œç›´æ¥è¿”å›å“åº”
            result_messages.append(response)
            
            # è¿”å›æ¶ˆæ¯é“¾ï¼ˆæµå¼æ¨¡æ‹Ÿï¼‰
            yield {"messages": result_messages}
    
    return agent_node


def create_web_expert_graph():
    """åˆ›å»ºWebå¼€å‘ä¸“å®¶æ™ºèƒ½ä½“å›¾ - ä¸¤èŠ‚ç‚¹æ¶æ„ï¼Œæ”¯æŒæµå¼è¾“å‡º"""
    
    # åˆ›å»ºçŠ¶æ€å›¾
    graph_builder = StateGraph(State)
    
    # åˆ›å»ºè§„åˆ’èŠ‚ç‚¹å’Œæ‰§è¡ŒèŠ‚ç‚¹
    web_planner = create_web_planner()
    web_agent = create_web_agent()
    
    # æ·»åŠ èŠ‚ç‚¹
    graph_builder.add_node("planner", web_planner)
    graph_builder.add_node("agent", web_agent)  # agentèŠ‚ç‚¹æ”¯æŒæµå¼è¾“å‡º
    
    # æ·»åŠ è¾¹ - ä¸¤èŠ‚ç‚¹æµç¨‹
    graph_builder.add_edge(START, "planner")
    graph_builder.add_edge("planner", "agent")
    graph_builder.add_edge("agent", END)
    
    # ç¼–è¯‘å›¾ - å¯ç”¨æµå¼æ”¯æŒ
    return graph_builder.compile()


# åˆ›å»ºå›¾å®ä¾‹ï¼ˆè¿™æ˜¯langgraph.jsonä¸­å¼•ç”¨çš„å…¥å£ç‚¹ï¼‰
web_expert_graph = create_web_expert_graph()