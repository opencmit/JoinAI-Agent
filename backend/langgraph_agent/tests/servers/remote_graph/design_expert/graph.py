"""
è®¾è®¡ä¸“å®¶æ™ºèƒ½ä½“ - ä¸¤èŠ‚ç‚¹æ¶æ„å®ç°
æ”¯æŒå›¾åƒç”Ÿæˆã€ä¿®æ”¹å’Œè®¾è®¡æ–‡ä»¶ç®¡ç†
"""

import os
import json
from typing import Dict, List, TypedDict, Annotated
from datetime import datetime

from langchain_core.messages import (
    AIMessage,
    SystemMessage,
    HumanMessage,
    ToolMessage,
    BaseMessage
)
from langchain.chat_models import init_chat_model
from langgraph.graph import StateGraph
from langgraph.graph.message import add_messages

# å¯¼å…¥è®¾è®¡å·¥å…·
import sys
import os
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))
from tools.design_tools import (
    generate_image,
    modify_image,
    analyze_design_request,
    save_design_file,
    create_design_preview
)


# å®šä¹‰çŠ¶æ€ç±»å‹
class State(TypedDict):
    messages: Annotated[List[BaseMessage], add_messages]


def create_design_planner():
    """åˆ›å»ºè®¾è®¡è§„åˆ’èŠ‚ç‚¹"""
    
    # ä»ç¯å¢ƒå˜é‡è·å–æ¨¡å‹é…ç½®
    model_name = os.getenv("OPENAI_MODEL", "gpt-4")
    base_url = os.getenv("OPENAI_BASE_URL")
    api_key = os.getenv("OPENAI_API_KEY")
    
    if not api_key:
        raise ValueError("OPENAI_API_KEYç¯å¢ƒå˜é‡æœªè®¾ç½®")
    
    # åˆå§‹åŒ–èŠå¤©æ¨¡å‹
    model_config = {"api_key": api_key}
    if base_url:
        model_config["base_url"] = base_url
        
    llm = init_chat_model(f"openai:{model_name}", **model_config)
    
    # è®¾è®¡è§„åˆ’ç³»ç»Ÿæç¤ºè¯
    planner_prompt = """ä½ æ˜¯ä¸“ä¸šè®¾è®¡è§„åˆ’åŠ©æ‰‹ï¼Œè´Ÿè´£åˆ†æè®¾è®¡éœ€æ±‚å¹¶åˆ¶å®šè®¾è®¡è®¡åˆ’ã€‚

ã€è§„åˆ’ä»»åŠ¡ã€‘
1. åˆ†æç”¨æˆ·çš„è®¾è®¡éœ€æ±‚ï¼ˆç”Ÿæˆæˆ–ä¿®æ”¹ï¼‰
2. ç¡®å®šè®¾è®¡ç±»å‹å’Œç›®æ ‡æ•ˆæœ
3. è¯†åˆ«è®¾è®¡é£æ ¼å’Œè§„æ ¼è¦æ±‚
4. åˆ¶å®šå…·ä½“çš„æ‰§è¡Œæ–¹æ¡ˆ
5. é¢„ä¼°è¾“å‡ºæ ¼å¼å’Œæ•°é‡

ã€è¾“å‡ºæ ¼å¼ã€‘
ğŸ“‹ è®¾è®¡è§„åˆ’æ–¹æ¡ˆï¼š

ã€è®¾è®¡ç›®æ ‡ã€‘
- ä»»åŠ¡ç±»å‹ï¼š[ç”Ÿæˆ/ä¿®æ”¹]
- è®¾è®¡å†…å®¹ï¼š[å…·ä½“æè¿°]
- æ ¸å¿ƒéœ€æ±‚ï¼š[è¦è¾¾æˆçš„æ•ˆæœ]

ã€è®¾è®¡è§„æ ¼ã€‘
- é£æ ¼å®šä½ï¼š[ç®€çº¦/ä¸“ä¸š/åˆ›æ„ç­‰]
- å°ºå¯¸è¦æ±‚ï¼š[å…·ä½“è§„æ ¼]
- æ•°é‡é¢„æœŸï¼š[ç”Ÿæˆæ•°é‡]

ã€æ‰§è¡Œç­–ç•¥ã€‘
- åˆ›æ„æ–¹å‘ï¼š[è®¾è®¡ç†å¿µ]
- æŠ€æœ¯è·¯çº¿ï¼š[å®ç°æ–¹å¼]
- è´¨é‡æ ‡å‡†ï¼š[è¯„ä¼°æ ‡å‡†]

ã€é¢„æœŸè¾“å‡ºã€‘
- äº¤ä»˜å½¢å¼ï¼š[å›¾ç‰‡/æ–‡ä»¶]
- è¾“å‡ºæ•°é‡ï¼š[å…·ä½“æ•°é‡]
- é™„åŠ è¯´æ˜ï¼š[ä½¿ç”¨å»ºè®®]"""

    async def planner_node(state: State) -> dict:
        """è®¾è®¡è§„åˆ’èŠ‚ç‚¹ - ä½¿ç”¨ ainvoke è°ƒç”¨"""
        messages = state["messages"]

        # æ„å»ºè§„åˆ’æ¶ˆæ¯
        planning_messages = [SystemMessage(content=planner_prompt)]

        # æ·»åŠ ç”¨æˆ·æ¶ˆæ¯
        if messages:
            last_message = messages[-1]
            content = last_message.content

            # è§£æè¾“å…¥ - æ”¯æŒå¤šç§æ ¼å¼
            try:
                query = ""
                image = ""

                if isinstance(content, str):
                    # å°è¯•è§£æä¸º JSON
                    if content.strip().startswith("{"):
                        try:
                            user_input = json.loads(content)
                            query = user_input.get("query", content)
                            image = user_input.get("image", "")
                        except:
                            # JSON è§£æå¤±è´¥ï¼Œä½¿ç”¨åŸå§‹å†…å®¹
                            query = content
                    else:
                        # çº¯æ–‡æœ¬è¾“å…¥
                        query = content
                else:
                    # éå­—ç¬¦ä¸²å†…å®¹
                    query = str(content)

                # å¤„ç†ç‰¹æ®Šè¾“å…¥
                if query == "ï¼Ÿ" or query == "?" or not query.strip():
                    query = "ç”Ÿæˆä¸€ä¸ªç¤ºä¾‹è®¾è®¡å›¾"

                # æ„å»ºè§„åˆ’è¯·æ±‚
                planning_request = f"è®¾è®¡éœ€æ±‚ï¼š{query}"
                if image:
                    planning_request += f"\nå·²æä¾›åŸå§‹å›¾ç‰‡ï¼šæ˜¯ï¼ˆéœ€è¦è¿›è¡Œä¿®æ”¹ï¼‰"
                else:
                    planning_request += f"\nåŸå§‹å›¾ç‰‡ï¼šæ— ï¼ˆéœ€è¦ç”Ÿæˆæ–°è®¾è®¡ï¼‰"

                planning_messages.append(HumanMessage(content=planning_request))
            except Exception as e:
                # ä½¿ç”¨åŸå§‹æ¶ˆæ¯
                planning_messages.extend(messages)
        
        # ä½¿ç”¨ ainvoke è¿›è¡Œå¼‚æ­¥è°ƒç”¨
        response = await llm.ainvoke(planning_messages)
        
        # è¿”å›è§„åˆ’ç»“æœ
        return {"messages": [response]}
    
    return planner_node


def create_design_agent():
    """åˆ›å»ºè®¾è®¡æ‰§è¡ŒèŠ‚ç‚¹"""
    
    # ä»ç¯å¢ƒå˜é‡è·å–æ¨¡å‹é…ç½®
    model_name = os.getenv("OPENAI_MODEL", "gpt-4")
    base_url = os.getenv("OPENAI_BASE_URL")
    api_key = os.getenv("OPENAI_API_KEY")
    
    if not api_key:
        raise ValueError("OPENAI_API_KEYç¯å¢ƒå˜é‡æœªè®¾ç½®")
    
    # åˆå§‹åŒ–èŠå¤©æ¨¡å‹
    model_config = {"api_key": api_key}
    if base_url:
        model_config["base_url"] = base_url
        
    llm = init_chat_model(f"openai:{model_name}", **model_config)
    
    # ç»‘å®šå·¥å…·åˆ°LLM
    tools = [
        generate_image,
        modify_image,
        analyze_design_request,
        save_design_file,
        create_design_preview
    ]
    llm_with_tools = llm.bind_tools(tools)
    
    # è®¾è®¡æ‰§è¡Œç³»ç»Ÿæç¤ºè¯
    system_prompt = """ä½ æ˜¯ä¸“ä¸šè®¾è®¡æ‰§è¡Œæ™ºèƒ½ä½“ï¼Œæ ¹æ®å‰é¢çš„è§„åˆ’æ–¹æ¡ˆæ‰§è¡Œè®¾è®¡ä»»åŠ¡ã€‚

ä½ çš„ä¸“é•¿åŒ…æ‹¬ï¼š
- å›¾åƒç”Ÿæˆï¼ˆæµ·æŠ¥ã€Logoã€å›¾æ ‡ã€æ¨ªå¹…ç­‰ï¼‰
- å›¾åƒä¿®æ”¹ï¼ˆé£æ ¼è½¬æ¢ã€æ•ˆæœè°ƒæ•´ã€å…ƒç´ ç¼–è¾‘ï¼‰
- è®¾è®¡æ–‡ä»¶ç®¡ç†ï¼ˆé¢„è§ˆç”Ÿæˆã€æ–‡ä»¶ä¿å­˜ï¼‰
- å¤šæ ·åŒ–è®¾è®¡æ–¹æ¡ˆï¼ˆæä¾›å¤šä¸ªé€‰é¡¹ï¼‰

ã€å¯ç”¨å·¥å…·ã€‘
ä½ å¯ä»¥ä½¿ç”¨ä»¥ä¸‹å·¥å…·æ¥æ‰§è¡Œè®¾è®¡ä»»åŠ¡ï¼š
- generate_image: ç”Ÿæˆæ–°å›¾åƒ
- modify_image: ä¿®æ”¹ç°æœ‰å›¾åƒ
- analyze_design_request: åˆ†æè®¾è®¡éœ€æ±‚
- save_design_file: ä¿å­˜è®¾è®¡æ–‡ä»¶
- create_design_preview: åˆ›å»ºé¢„è§ˆé¡µé¢

ã€æ‰§è¡Œè¦æ±‚ã€‘
1. ä¸¥æ ¼æŒ‰ç…§è§„åˆ’æ–¹æ¡ˆæ‰§è¡Œ
2. ç¡®ä¿è®¾è®¡è´¨é‡å’Œåˆ›æ„æ€§
3. æä¾›å¤šä¸ªè®¾è®¡é€‰é¡¹ä¾›é€‰æ‹©
4. ç”Ÿæˆç”¨æˆ·å‹å¥½çš„æè¿°ä¿¡æ¯
5. æŒ‰ç…§æŒ‡å®šæ ¼å¼è¿”å›ç»“æœ"""

    async def agent_node(state: State) -> dict:
        """è®¾è®¡æ‰§è¡ŒèŠ‚ç‚¹ - å¤„ç†è®¾è®¡ä»»åŠ¡å¹¶è¿”å›ç‰¹å®šæ ¼å¼"""
        messages = state["messages"]

        # è§£æç”¨æˆ·è¾“å…¥ - æŸ¥æ‰¾åŸå§‹ç”¨æˆ·æ¶ˆæ¯
        user_message = None
        for msg in messages:
            if hasattr(msg, 'type') and msg.type == 'human':
                user_message = msg
                break
            elif isinstance(msg, HumanMessage):
                user_message = msg
                break

        # å¦‚æœæ²¡æœ‰æ‰¾åˆ° human æ¶ˆæ¯ï¼Œä½¿ç”¨ç¬¬ä¸€æ¡æ¶ˆæ¯
        if not user_message and messages:
            user_message = messages[0]

        user_input = {}
        query = ""
        image = ""

        if user_message:
            content = user_message.content

            # è§£æè¾“å…¥ - æ”¯æŒå¤šç§æ ¼å¼
            if isinstance(content, str):
                # å°è¯•è§£æä¸º JSON
                if content.strip().startswith("{"):
                    try:
                        user_input = json.loads(content)
                        query = user_input.get("query", content)
                        image = user_input.get("image", "")
                    except:
                        # JSON è§£æå¤±è´¥ï¼Œä½¿ç”¨åŸå§‹å†…å®¹
                        query = content
                else:
                    # çº¯æ–‡æœ¬è¾“å…¥
                    query = content
            else:
                # éå­—ç¬¦ä¸²å†…å®¹
                query = str(content)

        # å¤„ç†ç‰¹æ®Šè¾“å…¥
        if query == "ï¼Ÿ" or query == "?" or not query.strip():
            query = "ç”Ÿæˆä¸€ä¸ªç¤ºä¾‹è®¾è®¡å›¾"
        
        # æ„å»ºæ‰§è¡Œæ¶ˆæ¯
        execution_messages = [SystemMessage(content=system_prompt)]
        
        # æ·»åŠ æ‰€æœ‰å†å²æ¶ˆæ¯ï¼ˆåŒ…æ‹¬è§„åˆ’ï¼‰
        if messages:
            execution_messages.extend(messages)
        
        # ç¬¬ä¸€æ¬¡è°ƒç”¨ - è·å–å·¥å…·è°ƒç”¨å†³å®š
        response = await llm_with_tools.ainvoke(execution_messages)
        
        # åˆå§‹åŒ–ç»“æœ
        result_messages = []
        generated_images = []
        generated_files = []
        task_description = ""
        
        # å¤„ç†å·¥å…·è°ƒç”¨ï¼ˆå¦‚æœæœ‰ï¼‰
        if hasattr(response, 'tool_calls') and response.tool_calls:
            # ä¿å­˜å¸¦æœ‰å·¥å…·è°ƒç”¨çš„ AIMessage
            result_messages.append(response)
            
            # æ‰§è¡Œå·¥å…·å¹¶æ”¶é›†ç»“æœ
            for tool_call in response.tool_calls:
                tool_name = tool_call['name']
                tool_args = tool_call['args']
                tool_id = tool_call.get('id', f"call_{tool_name}")
                
                # æŸ¥æ‰¾å¹¶æ‰§è¡Œå¯¹åº”çš„å·¥å…·
                tool_func = None
                for tool in tools:
                    if tool.name == tool_name:
                        tool_func = tool
                        break
                
                if tool_func:
                    try:
                        # æ‰§è¡Œå·¥å…·
                        tool_result = tool_func.invoke(tool_args)
                        
                        # æ ¹æ®å·¥å…·ç±»å‹å¤„ç†ç»“æœ
                        if tool_name in ['generate_image', 'modify_image']:
                            generated_images.extend(tool_result.get('images', []))
                            if tool_name == 'generate_image':
                                task_description = f"å·²æˆåŠŸç”Ÿæˆ'{query}'ç›¸å…³çš„è®¾è®¡å›¾ï¼Œå…±{len(tool_result.get('images', []))}å¼ "
                            else:
                                task_description = f"å·²æˆåŠŸä¿®æ”¹å›¾ç‰‡ï¼Œåº”ç”¨äº†'{query}'çš„æ•ˆæœ"
                        elif tool_name == 'save_design_file':
                            generated_files.append(tool_result)
                            task_description = f"å·²ä¿å­˜è®¾è®¡æ–‡ä»¶ï¼š{tool_result['name']}"
                        elif tool_name == 'create_design_preview':
                            # ä¿å­˜é¢„è§ˆæ–‡ä»¶
                            file_info = save_design_file.invoke({
                                'content': tool_result['html_content'],
                                'filename': tool_result['filename'],
                                'file_type': 'html'
                            })
                            generated_files.append(file_info)
                            task_description = f"å·²åˆ›å»ºè®¾è®¡é¢„è§ˆæ–‡ä»¶ï¼š{file_info['name']}"
                        
                        # åˆ›å»ºå·¥å…·æ¶ˆæ¯
                        tool_message = ToolMessage(
                            content=str(tool_result),
                            tool_call_id=tool_id
                        )
                        result_messages.append(tool_message)
                    except Exception as e:
                        # é”™è¯¯ä¹Ÿéœ€è¦è¿”å› ToolMessage
                        tool_message = ToolMessage(
                            content=f"å·¥å…·æ‰§è¡Œé”™è¯¯: {str(e)}",
                            tool_call_id=tool_id
                        )
                        result_messages.append(tool_message)
        
        # å¦‚æœæ²¡æœ‰é€šè¿‡å·¥å…·è°ƒç”¨ç”Ÿæˆå›¾ç‰‡ï¼Œç›´æ¥æ ¹æ®è¯·æ±‚ç±»å‹ç”Ÿæˆ
        if not generated_images and not generated_files:
            if image:
                # ä¿®æ”¹å›¾åƒ
                result = modify_image.invoke({
                    "image_base64": image,
                    "modification": query,
                    "style": "default"
                })
                generated_images = result.get("images", [])
                task_description = f"å·²æˆåŠŸä¿®æ”¹å›¾ç‰‡ï¼Œåº”ç”¨äº†'{query}'çš„æ•ˆæœï¼Œç”Ÿæˆäº†{len(generated_images)}ä¸ªè®¾è®¡æ–¹æ¡ˆ"
            else:
                # ç”Ÿæˆå›¾åƒ
                result = generate_image.invoke({
                    "prompt": query,
                    "style": "professional",
                    "size": "1024x1024"
                })
                generated_images = result.get("images", [])
                task_description = f"å·²æˆåŠŸç”Ÿæˆ'{query}'ï¼Œåˆ›å»ºäº†{len(generated_images)}å¼ è®¾è®¡å›¾"
        
        # æ„å»ºæœ€ç»ˆçš„è¿”å›æ¶ˆæ¯
        if generated_images:
            # è¿”å›å›¾ç‰‡ç±»å‹çš„ToolMessage
            final_message = ToolMessage(
                content=task_description,  # ç”¨æˆ·å‹å¥½çš„æè¿°
                tool_call_id="design_task",
                additional_kwargs={
                    "toolCalls": [{
                        "id": f"design_{datetime.now().timestamp()}",
                        "function": {
                            "name": "image",
                            "arguments": json.dumps(generated_images)  # å›¾ç‰‡base64æ•°ç»„
                        },
                        "type": "function"
                    }],
                    "name": "image"
                }
            )
        elif generated_files:
            # è¿”å›æ–‡ä»¶ç±»å‹çš„ToolMessage
            file_info = generated_files[0]  # ä½¿ç”¨ç¬¬ä¸€ä¸ªæ–‡ä»¶
            final_message = ToolMessage(
                content=task_description,  # ç”¨æˆ·å‹å¥½çš„æè¿°
                tool_call_id="design_file",
                additional_kwargs={
                    "toolCalls": [{
                        "id": f"file_{datetime.now().timestamp()}",
                        "function": {
                            "name": "files",
                            "arguments": json.dumps({
                                "name": file_info["name"],
                                "path": file_info["path"],
                                "date": file_info["date"]
                            })
                        },
                        "type": "function"
                    }],
                    "name": "files"
                }
            )
        else:
            # å¦‚æœæ²¡æœ‰ç”Ÿæˆå†…å®¹ï¼Œè¿”å›æ™®é€šæ¶ˆæ¯
            final_message = AIMessage(content="è®¾è®¡ä»»åŠ¡å·²å®Œæˆï¼Œä½†æœªç”Ÿæˆå…·ä½“å†…å®¹ã€‚è¯·æä¾›æ›´è¯¦ç»†çš„éœ€æ±‚ã€‚")
        
        result_messages.append(final_message)
        
        # è¿”å›å®Œæ•´çš„æ¶ˆæ¯é“¾
        return {"messages": result_messages}
    
    return agent_node


def create_design_expert_graph():
    """åˆ›å»ºè®¾è®¡ä¸“å®¶æ™ºèƒ½ä½“å›¾ - ä¸¤èŠ‚ç‚¹æ¶æ„"""
    
    # åˆ›å»ºçŠ¶æ€å›¾
    graph_builder = StateGraph(State)
    
    # åˆ›å»ºèŠ‚ç‚¹
    planner = create_design_planner()
    agent = create_design_agent()
    
    # æ·»åŠ èŠ‚ç‚¹åˆ°å›¾
    graph_builder.add_node("planner", planner)
    graph_builder.add_node("agent", agent)
    
    # å®šä¹‰è¾¹ï¼ˆå·¥ä½œæµï¼‰
    graph_builder.set_entry_point("planner")  # ä»plannerå¼€å§‹
    graph_builder.add_edge("planner", "agent")  # planner -> agent
    graph_builder.set_finish_point("agent")  # agentç»“æŸ
    
    # ç¼–è¯‘å›¾
    graph = graph_builder.compile()
    
    return graph


# åˆ›å»ºå¹¶å¯¼å‡ºå›¾å®ä¾‹
design_expert_graph = create_design_expert_graph()

# è¿™å…è®¸LangGraph CLIç›´æ¥è¿è¡Œè¿™ä¸ªå›¾
if __name__ == "__main__":
    import asyncio
    
    async def test():
        # æµ‹è¯•å›¾åƒç”Ÿæˆ
        test_input = {
            "messages": [
                HumanMessage(content=json.dumps({
                    "query": "ç”Ÿæˆä¸€ä¸ªæ ¡åº†æµ·æŠ¥",
                    "image": ""
                }))
            ]
        }
        
        result = await design_expert_graph.ainvoke(test_input)
        print("ç”Ÿæˆæµ‹è¯•ç»“æœ:", result)
        
        # æµ‹è¯•å›¾åƒä¿®æ”¹
        test_input2 = {
            "messages": [
                HumanMessage(content=json.dumps({
                    "query": "å¯¹è¿™ä¸ªå›¾ç‰‡è°ƒä¸€ä¸‹é£æ ¼ï¼Œæ”¹ä¸ºç®€çº¦é£",
                    "image": "data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAUA..."
                }))
            ]
        }
        
        result2 = await design_expert_graph.ainvoke(test_input2)
        print("ä¿®æ”¹æµ‹è¯•ç»“æœ:", result2)
    
    # è¿è¡Œæµ‹è¯•
    # asyncio.run(test())