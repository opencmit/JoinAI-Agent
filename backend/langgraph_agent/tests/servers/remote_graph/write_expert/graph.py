"""
ä¸“ä¸šå†™ä½œæ™ºèƒ½ä½“æœåŠ¡ - ä¸¤èŠ‚ç‚¹æ¶æ„ï¼ˆplanner + agentï¼‰
"""

import os
import sys
from typing import Annotated
from typing_extensions import TypedDict

from langchain_core.messages import BaseMessage,SystemMessage, HumanMessage, AIMessage, ToolMessage
from langchain.chat_models import init_chat_model
from langgraph.graph import StateGraph, START, END
from langgraph.graph.message import add_messages

# æ·»åŠ toolsç›®å½•åˆ°Pythonè·¯å¾„
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..'))
from tools.base_tools import get_current_time, search_web, read_file, write_file, word_count
from tools.write_tools import check_grammar, format_citation, count_paragraphs


class State(TypedDict):
    """å›¾çŠ¶æ€å®šä¹‰"""
    messages: Annotated[list, add_messages]


def create_writing_planner():
    """åˆ›å»ºå†™ä½œè§„åˆ’èŠ‚ç‚¹"""
    
    # ä»ç¯å¢ƒå˜é‡è·å–æ¨¡å‹é…ç½®
    model_name = os.getenv("OPENAI_MODEL", "gpt-4")
    base_url = os.getenv("OPENAI_BASE_URL")
    api_key = os.getenv("OPENAI_API_KEY")
    
    if not api_key:
        raise ValueError("OPENAI_API_KEYç¯å¢ƒå˜é‡æœªè®¾ç½®")
    
    # åˆå§‹åŒ–èŠå¤©æ¨¡å‹
    model_config = {"api_key": api_key}
    if base_url:
        model_config["base_url"] = base_url
        
    llm = init_chat_model(f"openai:{model_name}", **model_config)
    
    # å†™ä½œè§„åˆ’ç³»ç»Ÿæç¤ºè¯
    planner_prompt = """ä½ æ˜¯ä¸“ä¸šå†™ä½œè§„åˆ’åŠ©æ‰‹ï¼Œè´Ÿè´£åˆ†æå†™ä½œéœ€æ±‚å¹¶åˆ¶å®šå†™ä½œè®¡åˆ’ã€‚

ã€è§„åˆ’ä»»åŠ¡ã€‘
1. åˆ†æç”¨æˆ·çš„å†™ä½œéœ€æ±‚å’Œç›®æ ‡
2. ç¡®å®šæ–‡æ¡£ç±»å‹å’Œç›®æ ‡è¯»è€…
3. è®¾è®¡å†…å®¹ç»“æ„å’Œé€»è¾‘æ¡†æ¶
4. è§„åˆ’å†™ä½œé£æ ¼å’Œè¯­è¨€åŸºè°ƒ
5. åˆ¶å®šè´¨é‡æ ‡å‡†å’Œæ£€æŸ¥è¦ç‚¹

ã€è¾“å‡ºæ ¼å¼ã€‘
ğŸ“‹ å†™ä½œè§„åˆ’æ–¹æ¡ˆï¼š

ã€å†™ä½œç›®æ ‡ã€‘
- æ–‡æ¡£ç±»å‹ï¼š[æŠ¥å‘Š/æ–‡ç« /ææ¡ˆç­‰]
- æ ¸å¿ƒç›®çš„ï¼š[è¦è¾¾æˆçš„ç›®æ ‡]

ã€è¯»è€…åˆ†æã€‘
- ç›®æ ‡è¯»è€…ï¼š[è¯»è€…ç¾¤ä½“ç‰¹å¾]
- é˜…è¯»éœ€æ±‚ï¼š[è¯»è€…æœŸæœ›è·å¾—ä»€ä¹ˆ]

ã€å†…å®¹æ¶æ„ã€‘
- æ€»ä½“ç»“æ„ï¼š[å¼•è¨€-ä¸»ä½“-ç»“è®ºæ¡†æ¶]
- ç« èŠ‚å¤§çº²ï¼š[å…·ä½“ç« èŠ‚å’Œè¦ç‚¹]
- é€»è¾‘è„‰ç»œï¼š[è®ºè¿°å±•å¼€æ–¹å¼]

ã€å†™ä½œé£æ ¼ã€‘
- è¯­è¨€é£æ ¼ï¼š[æ­£å¼/é€šä¿—/ä¸“ä¸šç­‰]
- è¯­æ°”åŸºè°ƒï¼š[å®¢è§‚/äº²åˆ‡/æƒå¨ç­‰]
- è¡¨è¾¾ç‰¹ç‚¹ï¼š[ç®€æ´/è¯¦ç»†/ç”ŸåŠ¨ç­‰]

ã€è´¨é‡è¦æ±‚ã€‘
- ä¿¡æ¯å‡†ç¡®æ€§ï¼š[äº‹å®æ ¸æŸ¥è¦ç‚¹]
- é€»è¾‘ä¸¥å¯†æ€§ï¼š[è®ºè¯è¦æ±‚]
- å¯è¯»æ€§æ ‡å‡†ï¼š[æ˜“è¯»æ€§æŒ‡æ ‡]"""

    async def planner_node(state: State) -> dict:
        """å†™ä½œè§„åˆ’èŠ‚ç‚¹ - ä½¿ç”¨ ainvoke è°ƒç”¨"""
        messages = state["messages"]
        
        # æ„å»ºè§„åˆ’æ¶ˆæ¯
        planning_messages = [SystemMessage(content=planner_prompt)]
        
        # æ·»åŠ ç”¨æˆ·æ¶ˆæ¯
        if messages:
            planning_messages.extend(messages)
        
        # ä½¿ç”¨ ainvoke è¿›è¡Œå¼‚æ­¥è°ƒç”¨
        response = await llm.ainvoke(planning_messages)
        
        # è¿”å›è§„åˆ’ç»“æœï¼ˆresponseå·²ç»æ˜¯AIMessageå¯¹è±¡ï¼‰
        return {"messages": [response]}
    
    return planner_node


def create_writing_agent():
    """åˆ›å»ºä¸“ä¸šå†™ä½œæ‰§è¡ŒèŠ‚ç‚¹"""
    
    # ä»ç¯å¢ƒå˜é‡è·å–æ¨¡å‹é…ç½®
    model_name = os.getenv("OPENAI_MODEL", "gpt-4")
    base_url = os.getenv("OPENAI_BASE_URL")
    api_key = os.getenv("OPENAI_API_KEY")
    
    if not api_key:
        raise ValueError("OPENAI_API_KEYç¯å¢ƒå˜é‡æœªè®¾ç½®")
    
    # åˆå§‹åŒ–èŠå¤©æ¨¡å‹
    model_config = {"api_key": api_key}
    if base_url:
        model_config["base_url"] = base_url
        
    llm = init_chat_model(f"openai:{model_name}", **model_config)
    
    # ç»‘å®šå·¥å…·åˆ°LLM
    tools = [
        get_current_time,
        search_web,
        read_file, 
        write_file,
        word_count,
        check_grammar,
        format_citation,
        count_paragraphs
    ]
    llm_with_tools = llm.bind_tools(tools)
    
    # ä¸“ä¸šå†™ä½œæ‰§è¡Œç³»ç»Ÿæç¤ºè¯
    system_prompt = """ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„å†™ä½œæ™ºèƒ½ä½“ï¼Œæ ¹æ®å‰é¢çš„è§„åˆ’æ–¹æ¡ˆæ‰§è¡Œå†™ä½œä»»åŠ¡ã€‚

ä½ çš„ä¸“é•¿åŒ…æ‹¬ï¼š
- å•†ä¸šæ–‡æ¡£æ’°å†™ï¼ˆæŠ¥å‘Šã€ææ¡ˆã€å¤‡å¿˜å½•ç­‰ï¼‰
- æŠ€æœ¯æ–‡æ¡£ç¼–å†™ï¼ˆè¯´æ˜ä¹¦ã€ç”¨æˆ·æŒ‡å—ã€APIæ–‡æ¡£ç­‰ï¼‰
- åˆ›æ„å†…å®¹åˆ›ä½œï¼ˆæ–‡ç« ã€åšå®¢ã€è¥é”€æ–‡æ¡ˆç­‰ï¼‰
- å­¦æœ¯å†™ä½œï¼ˆè®ºæ–‡ã€ç ”ç©¶æŠ¥å‘Šã€åˆ†ææ–‡ç« ç­‰ï¼‰
- å¤šç§æ–‡ä½“å’Œé£æ ¼é€‚é…

ã€å¯ç”¨å·¥å…·ã€‘
ä½ å¯ä»¥ä½¿ç”¨ä»¥ä¸‹å·¥å…·æ¥è¾…åŠ©å†™ä½œï¼š
- get_current_time: è·å–å½“å‰æ—¶é—´
- search_web: æœç´¢ç½‘ç»œè·å–å‚è€ƒä¿¡æ¯
- read_file/write_file: è¯»å–æˆ–ä¿å­˜æ–‡æ¡£
- word_count: ç»Ÿè®¡å­—æ•°å’Œæ®µè½
- check_grammar: æ£€æŸ¥è¯­æ³•é—®é¢˜
- format_citation: æ ¼å¼åŒ–å¼•ç”¨æ–‡çŒ®
- count_paragraphs: åˆ†ææ®µè½ç»“æ„

ã€æ‰§è¡Œè¦æ±‚ã€‘
åŸºäºå‰é¢çš„è§„åˆ’æ–¹æ¡ˆï¼Œåˆ›ä½œé«˜è´¨é‡çš„ä¸“ä¸šå†…å®¹ï¼š
1. ä¸¥æ ¼éµå¾ªè§„åˆ’çš„ç»“æ„å’Œæ¡†æ¶
2. ä¿æŒè§„åˆ’ç¡®å®šçš„å†™ä½œé£æ ¼å’Œè¯­æ°”
3. æ»¡è¶³ç›®æ ‡è¯»è€…çš„é˜…è¯»éœ€æ±‚
4. ç¡®ä¿å†…å®¹å‡†ç¡®ã€é€»è¾‘æ¸…æ™°ã€è¯­è¨€æµç•…
5. æ³¨é‡æ ¼å¼è§„èŒƒå’Œä¸“ä¸šæ€§
6. é€‚å½“ä½¿ç”¨å·¥å…·å¢å¼ºå†…å®¹è´¨é‡

è¾“å‡ºå®Œæ•´ã€è¯¦ç»†ã€å¯ç›´æ¥ä½¿ç”¨çš„æ–‡æ¡£å†…å®¹ã€‚"""

    async def agent_node(state: State) -> dict:
        """ä¸“ä¸šå†™ä½œæ‰§è¡ŒèŠ‚ç‚¹ - ä½¿ç”¨ ainvoke è°ƒç”¨"""
        messages = state["messages"]
        
        # æ„å»ºæ‰§è¡Œæ¶ˆæ¯ï¼ˆåŒ…å«è§„åˆ’ä¿¡æ¯ï¼‰
        execution_messages = [SystemMessage(content=system_prompt)]
        
        # æ·»åŠ æ‰€æœ‰å†å²æ¶ˆæ¯ï¼ˆåŒ…æ‹¬è§„åˆ’ï¼‰
        if messages:
            execution_messages.extend(messages)
        
        # ç¬¬ä¸€æ¬¡è°ƒç”¨ - è·å–å·¥å…·è°ƒç”¨å†³å®š
        response = await llm_with_tools.ainvoke(execution_messages)
        
        # åˆå§‹åŒ–ç»“æœæ¶ˆæ¯åˆ—è¡¨
        result_messages = []
        
        # å¤„ç†å·¥å…·è°ƒç”¨ï¼ˆå¦‚æœæœ‰ï¼‰
        if hasattr(response, 'tool_calls') and response.tool_calls:
            # ä¿å­˜å¸¦æœ‰å·¥å…·è°ƒç”¨çš„ AIMessage
            result_messages.append(response)
            
            # æ‰§è¡Œå·¥å…·å¹¶åˆ›å»º ToolMessage
            for tool_call in response.tool_calls:
                tool_name = tool_call['name']
                tool_args = tool_call['args']
                tool_id = tool_call.get('id', f"call_{tool_name}")
                
                # æŸ¥æ‰¾å¹¶æ‰§è¡Œå¯¹åº”çš„å·¥å…·
                tool_func = None
                for tool in tools:
                    if tool.name == tool_name:
                        tool_func = tool
                        break
                
                if tool_func:
                    try:
                        # æ‰§è¡Œå·¥å…·
                        tool_result = tool_func.invoke(tool_args)
                        # åˆ›å»º ToolMessage
                        tool_message = ToolMessage(
                            content=str(tool_result),
                            tool_call_id=tool_id
                        )
                        result_messages.append(tool_message)
                    except Exception as e:
                        # é”™è¯¯ä¹Ÿéœ€è¦è¿”å› ToolMessage
                        tool_message = ToolMessage(
                            content=f"å·¥å…·æ‰§è¡Œé”™è¯¯: {str(e)}",
                            tool_call_id=tool_id
                        )
                        result_messages.append(tool_message)
            
            # ç¬¬äºŒæ¬¡è°ƒç”¨ - åŸºäºå·¥å…·ç»“æœç”Ÿæˆæœ€ç»ˆå“åº”
            final_messages = execution_messages + result_messages
            final_response = await llm.ainvoke(final_messages)
            result_messages.append(final_response)
        else:
            # æ²¡æœ‰å·¥å…·è°ƒç”¨ï¼Œç›´æ¥è¿”å›å“åº”
            result_messages.append(response)
        
        # è¿”å›å®Œæ•´çš„æ¶ˆæ¯é“¾
        return {"messages": result_messages}
    
    return agent_node


def create_write_expert_graph():
    """åˆ›å»ºä¸“ä¸šå†™ä½œæ™ºèƒ½ä½“å›¾ - ä¸¤èŠ‚ç‚¹æ¶æ„"""
    
    # åˆ›å»ºçŠ¶æ€å›¾
    graph_builder = StateGraph(State)
    
    # åˆ›å»ºè§„åˆ’èŠ‚ç‚¹å’Œæ‰§è¡ŒèŠ‚ç‚¹
    writing_planner = create_writing_planner()
    writing_agent = create_writing_agent()
    
    # æ·»åŠ èŠ‚ç‚¹
    graph_builder.add_node("planner", writing_planner)
    graph_builder.add_node("agent", writing_agent)
    
    # æ·»åŠ è¾¹ - ä¸¤èŠ‚ç‚¹æµç¨‹
    graph_builder.add_edge(START, "planner")
    graph_builder.add_edge("planner", "agent")
    graph_builder.add_edge("agent", END)
    
    # ç¼–è¯‘å›¾
    return graph_builder.compile()


# åˆ›å»ºå›¾å®ä¾‹ï¼ˆè¿™æ˜¯langgraph.jsonä¸­å¼•ç”¨çš„å…¥å£ç‚¹ï¼‰
write_expert_graph = create_write_expert_graph()