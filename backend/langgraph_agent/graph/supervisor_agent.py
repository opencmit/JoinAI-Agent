"""
Supervisor æ™ºèƒ½ä½“èŠ‚ç‚¹å®ç°
è´Ÿè´£è·¯ç”±å†³ç­–å’Œæ™ºèƒ½ä½“åè°ƒ
"""

'''
import os
import logging
import asyncio
from typing import Dict, Any, Optional
from langchain_openai import ChatOpenAI
from langchain_core.messages import HumanMessage, AIMessage
from langchain_core.runnables import RunnableConfig

from langgraph_agent.graph.state import AgentState
from langgraph_agent.config import llm_config
from langgraph_agent.prompts.supervisor_prompt import (
    create_supervisor_decision_prompt,
    parse_supervisor_decision,
    get_latest_user_message
)

logger = logging.getLogger(__name__)

async def supervisor_agent_node(state: AgentState, config: RunnableConfig) -> AgentState:
    """
    Supervisor æ™ºèƒ½ä½“èŠ‚ç‚¹ - è´Ÿè´£è·¯ç”±å†³ç­–
    
    Args:
        state: æ™ºèƒ½ä½“çŠ¶æ€
        config: è¿è¡Œé…ç½®
        
    Returns:
        AgentState: æ›´æ–°åçš„çŠ¶æ€ï¼ŒåŒ…å«è·¯ç”±å†³ç­–
    """
    logger.info("=== Supervisor æ™ºèƒ½ä½“å¼€å§‹è·¯ç”±å†³ç­– ===")
    
    # ğŸ”¥ æ–°å¢ï¼šæ›´æ–°è¿­ä»£è®¡æ•°å™¨ï¼Œé˜²æ­¢æ— é™å¾ªç¯
    state["iteration_count"] = state.get("iteration_count", 0) + 1
    current_iteration = state["iteration_count"]
    max_iterations = state.get("max_iterations", 50)
    
    logger.info(f"ğŸ”„ å½“å‰è¿­ä»£æ¬¡æ•°: {current_iteration}/{max_iterations}")
    
    # å¦‚æœè¿­ä»£æ¬¡æ•°æ¥è¿‘ä¸Šé™ï¼Œè®°å½•è­¦å‘Š
    if current_iteration >= max_iterations * 0.8:  # 80%æ—¶å¼€å§‹è­¦å‘Š
        logger.warning(f"âš ï¸ è¿­ä»£æ¬¡æ•°æ¥è¿‘ä¸Šé™: {current_iteration}/{max_iterations}")
    
    try:
        # 1. æ£€æŸ¥æ˜¯å¦æœ‰A2Aæ™ºèƒ½ä½“ï¼Œå¦‚æœæ²¡æœ‰ç›´æ¥è·¯ç”±åˆ°é€šç”¨æ™ºèƒ½ä½“
        a2a_agents = state.get("a2a_agents", [])
        if not a2a_agents:
            logger.info("æ²¡æœ‰A2Aæ™ºèƒ½ä½“ï¼Œç›´æ¥è·¯ç”±åˆ°é€šç”¨æ™ºèƒ½ä½“")
            state["route_to_a2a"] = None
            state["supervisor_decision"] = {
                "analysis": "æ²¡æœ‰é…ç½®A2Aæ™ºèƒ½ä½“",
                "recommended_agent": "é€šç”¨æ™ºèƒ½ä½“",
                "confidence": 1.0,
                "reasoning": "ç³»ç»Ÿä¸­æ²¡æœ‰é…ç½®A2Aæ™ºèƒ½ä½“ï¼Œç›´æ¥ä½¿ç”¨é€šç”¨æ™ºèƒ½ä½“å¤„ç†",
                "fallback": "é€šç”¨æ™ºèƒ½ä½“"
            }
            return state
        
        # 2. è·å–ç”¨æˆ·æœ€æ–°æ¶ˆæ¯å’Œå·¥ä½œæµçŠ¶æ€
        user_message = get_latest_user_message(state)
        logger.info(f"ç”¨æˆ·æ¶ˆæ¯: {user_message}")
        
        # ğŸ”¥ æ£€æŸ¥æ˜¯å¦ä¸ºå¤šæ­¥éª¤å·¥ä½œæµçš„åç»­æ­¥éª¤
        workflow_plan = state.get("workflow_plan")
        current_step_index = state.get("current_step_index", 0)
        execution_results = state.get("execution_results", {})
        
        # ğŸ”¥ é‡ç½®å½“å‰æ­¥éª¤å®Œæˆæ ‡å¿—ï¼ˆåœ¨SupervisorèŠ‚ç‚¹å†…é‡ç½®ï¼‰
        if state.get("current_step_completed", False):
            state["current_step_completed"] = False
            logger.info("ğŸ”„ é‡ç½®å½“å‰æ­¥éª¤å®Œæˆæ ‡å¿—")
        
        # ğŸ”¥ æ£€æŸ¥æ˜¯å¦ä¸ºå¤šæ­¥éª¤å·¥ä½œæµï¼ˆåŒ…æ‹¬åˆå§‹çŠ¶æ€å’Œåç»­æ­¥éª¤ï¼‰
        if workflow_plan:
            workflow_type = workflow_plan.get("workflow_type", "single_step")
            total_steps = workflow_plan.get("total_steps", 1)
            
            logger.info(f"ğŸ”„ å¤„ç†å·¥ä½œæµï¼Œç±»å‹: {workflow_type}, å½“å‰æ­¥éª¤ç´¢å¼•: {current_step_index}, æ€»æ­¥éª¤: {total_steps}")
            
            # ğŸ”¥ å…³é”®ä¿®å¤ï¼šæ£€æŸ¥å•æ­¥ä»»åŠ¡æ˜¯å¦å·²å®Œæˆ
            if workflow_type == "single_step":
                # å•æ­¥ä»»åŠ¡ï¼šæ£€æŸ¥æ˜¯å¦æœ‰messagesä¸”ä»»åŠ¡å·²å¼€å§‹
                messages = state.get("messages", [])
                has_agent_response = False
                
                # æ£€æŸ¥æ˜¯å¦æœ‰æ¥è‡ªæ™ºèƒ½ä½“çš„å“åº”ï¼ˆä¸åŒ…æ‹¬supervisorçš„å†³ç­–æ¶ˆæ¯ï¼‰
                for msg in reversed(messages):
                    if hasattr(msg, 'content') and isinstance(msg.content, str):
                        # è·³è¿‡supervisorçš„è·¯ç”±å†³ç­–æ¶ˆæ¯
                        if not msg.content.startswith("ğŸ”€ **è·¯ç”±å†³ç­–**"):
                            has_agent_response = True
                            break
                
                if has_agent_response and current_step_index >= total_steps:
                    logger.info("ğŸ‰ å•æ­¥ä»»åŠ¡å·²å®Œæˆ")
                    state["completed"] = True
                    # ä¸ºå•æ­¥ä»»åŠ¡æ·»åŠ å®Œæˆç¡®è®¤æ¶ˆæ¯
                    completion_message = "âœ… **ä»»åŠ¡å®Œæˆ** - æ‚¨çš„è¯·æ±‚å·²ç»å¤„ç†å®Œæ¯•ã€‚"
                    state["messages"].append(AIMessage(content=completion_message))
                    return state
            elif workflow_type == "multi_step":
                # å¤šæ­¥éª¤å·¥ä½œæµé€»è¾‘ä¿æŒä¸å˜
                logger.info(f"ğŸ”„ å¤„ç†å¤šæ­¥éª¤å·¥ä½œæµï¼Œå½“å‰æ­¥éª¤ç´¢å¼•: {current_step_index}")
                
                # æ£€æŸ¥æ˜¯å¦è¿˜æœ‰å¾…æ‰§è¡Œçš„æ­¥éª¤
                if current_step_index < total_steps:
                    # è·å–ä¸‹ä¸€æ­¥éª¤ä¿¡æ¯
                    steps = workflow_plan.get("steps", [])
                    if current_step_index < len(steps):
                        next_step = steps[current_step_index]
                        next_agent_type = next_step.get("agent_type", "é€šç”¨æ™ºèƒ½ä½“")
                        next_description = next_step.get("description", "")
                        
                        logger.info(f"ğŸ¯ æ‰§è¡Œå·¥ä½œæµæ­¥éª¤ {current_step_index + 1}/{total_steps}: {next_description}")
                        
                        # æ„å»ºåŒ…å«ä¹‹å‰æ‰§è¡Œç»“æœçš„ä»»åŠ¡æŒ‡ä»¤
                        task_instruction = build_workflow_step_instruction(
                            user_message, 
                            next_step, 
                            execution_results, 
                            current_step_index + 1
                        )
                        
                        # è®¾ç½®ä¸‹ä¸€æ­¥éª¤çš„è·¯ç”±å†³ç­–
                        decision = {
                            "analysis": f"å¤šæ­¥éª¤å·¥ä½œæµç¬¬{current_step_index + 1}æ­¥ï¼Œå…±{total_steps}æ­¥",
                            "recommended_agent": next_agent_type,
                            "confidence": 0.95,
                            "reasoning": f"æ ¹æ®å·¥ä½œæµè®¡åˆ’æ‰§è¡Œç¬¬{current_step_index + 1}æ­¥ï¼š{next_description}",
                            "task_instruction": task_instruction,
                            "fallback": "é€šç”¨æ™ºèƒ½ä½“",
                            "workflow_type": "multi_step",
                            "workflow_plan": workflow_plan
                        }
                        
                        if decision["recommended_agent"] == "é€šç”¨æ™ºèƒ½ä½“":
                            state["route_to_a2a"] = None
                        else:
                            state["route_to_a2a"] = decision["recommended_agent"]
                        
                        state["supervisor_decision"] = decision
                        logger.info(f"ğŸ”„ å·¥ä½œæµæ­¥éª¤è·¯ç”±: {decision['recommended_agent']}")
                        
                        # ğŸ”¥ è®¾ç½®å·¥ä½œæµè®¡åˆ’å¹¶æ›´æ–°æ­¥éª¤ç´¢å¼•ï¼ˆç»§ç»­ä¿æŒå·¥ä½œæµçŠ¶æ€ï¼‰
                        # ğŸ”¥ å…³é”®ä¿®å¤ï¼šç¡®ä¿workflow_planä¸­åŒ…å«workflow_typeå­—æ®µ
                        if "workflow_type" not in workflow_plan:
                            workflow_plan["workflow_type"] = "multi_step"
                        state["workflow_plan"] = workflow_plan
                        state["current_step_index"] = current_step_index
                        
                        return state
                else:
                    # æ‰€æœ‰æ­¥éª¤å·²å®Œæˆï¼Œæ ‡è®°å·¥ä½œæµå®Œæˆ
                    logger.info("ğŸ‰ å¤šæ­¥éª¤å·¥ä½œæµå·²å®Œæˆæ‰€æœ‰æ­¥éª¤")
                    state["completed"] = True
                    completion_message = create_workflow_completion_message(execution_results, workflow_plan)
                    state["messages"].append(AIMessage(content=completion_message))
                    return state
        
        # 3. åˆ›å»ºLLMå®ä¾‹è¿›è¡Œå†³ç­–
        llm_instance = create_supervisor_llm_instance(state, config)
        
        # 4. å°è¯•ä½¿ç”¨LLMè¿›è¡Œæ™ºèƒ½å†³ç­–
        decision = None
        if llm_instance:
            try:
                decision = await make_llm_decision(state, user_message, llm_instance)
                logger.info(f"LLMå†³ç­–ç»“æœ: {decision}")
            except Exception as e:
                logger.error(f"LLMå†³ç­–å¤±è´¥: {str(e)}")
                decision = None
        
        # 5. å¦‚æœLLMå†³ç­–å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤çš„é€šç”¨æ™ºèƒ½ä½“å†³ç­–
        if not decision:
            logger.warning("LLMå†³ç­–å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤é€šç”¨æ™ºèƒ½ä½“å†³ç­–")
            
            # è®°å½•å†³ç­–å¤±è´¥çš„è¯¦ç»†ä¿¡æ¯ç”¨äºç›‘æ§
            failure_info = {
                "user_message_length": len(user_message),
                "a2a_agents_count": len(a2a_agents),
                "failed_agents_count": len(state.get("failed_a2a_agents", [])),
                "iteration_count": current_iteration
            }
            logger.info(f"LLMå†³ç­–å¤±è´¥è¯¦æƒ…: {failure_info}")
            
            # æ„å»ºæ›´è¯¦ç»†çš„reasoningä¿¡æ¯
            reasoning_parts = ["LLMè·¯ç”±å†³ç­–å¤±è´¥"]
            if state.get("failed_a2a_agents"):
                reasoning_parts.append(f"å·²æ’é™¤{len(state.get('failed_a2a_agents', []))}ä¸ªå¤±è´¥çš„æ™ºèƒ½ä½“")
            if len(a2a_agents) > 0:
                reasoning_parts.append(f"ç³»ç»Ÿä¸­æœ‰{len(a2a_agents)}ä¸ªå¯ç”¨çš„A2Aæ™ºèƒ½ä½“")
            reasoning_parts.append("ä¸ºç¡®ä¿ä»»åŠ¡èƒ½å¤Ÿå®Œæˆï¼Œä½¿ç”¨é€šç”¨æ™ºèƒ½ä½“å¤„ç†ç”¨æˆ·è¯·æ±‚")
            
            decision = {
                "analysis": "LLMå†³ç­–å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤fallbackç­–ç•¥",
                "recommended_agent": "é€šç”¨æ™ºèƒ½ä½“",
                "confidence": 0.7,
                "reasoning": "ï¼›".join(reasoning_parts),
                "fallback": "é€šç”¨æ™ºèƒ½ä½“",
                "llm_failure": True,  # æ ‡è®°è¿™æ˜¯LLMå¤±è´¥åçš„å†³ç­–
                "failure_info": failure_info
            }
        
        # ğŸš¨ å…³é”®ä¿®å¤ï¼šå¼ºåˆ¶è¿‡æ»¤å¤±è´¥çš„æ™ºèƒ½ä½“ï¼Œé˜²æ­¢LLMé‡å¤æ¨è
        failed_agents = state.get("failed_a2a_agents", [])
        if decision and decision.get("recommended_agent") in failed_agents:
            logger.warning(f"ğŸš« LLMæ¨èçš„æ™ºèƒ½ä½“ {decision['recommended_agent']} å·²å¤±è´¥ï¼Œå¼ºåˆ¶fallbackåˆ°é€šç”¨æ™ºèƒ½ä½“")
            
            # è·å–å¤±è´¥æ™ºèƒ½ä½“çš„åç§°ç”¨äºreasoning
            failed_agent_name = decision['recommended_agent']
            original_reasoning = decision.get('reasoning', 'åŸå§‹LLMæ¨è')
            
            decision = {
                "analysis": f"LLMæ¨èçš„æ™ºèƒ½ä½“å·²å¤±è´¥: {decision['recommended_agent']}",
                "recommended_agent": "é€šç”¨æ™ºèƒ½ä½“",
                "confidence": 0.8,
                "reasoning": f"åŸæœ¬æ¨èä½¿ç”¨ {failed_agent_name}ï¼Œä½†è¯¥æ™ºèƒ½ä½“ä¹‹å‰æ‰§è¡Œå¤±è´¥ã€‚ä¸ºç¡®ä¿ä»»åŠ¡èƒ½å¤Ÿå®Œæˆï¼Œç°æ”¹ä¸ºä½¿ç”¨é€šç”¨æ™ºèƒ½ä½“å¤„ç†ã€‚åŸå§‹æ¨èç†ç”±ï¼š{original_reasoning}",
                "fallback": "é€šç”¨æ™ºèƒ½ä½“",
                "failure_reason": f"æ™ºèƒ½ä½“ {failed_agent_name} æ‰§è¡Œå¤±è´¥",
                "retry_count": state.get("supervisor_retry_count", 0)
            }

        # ğŸ”¥ æ–°å¢ï¼šéªŒè¯æ¨èçš„æ™ºèƒ½ä½“IDæ ¼å¼æ˜¯å¦æ­£ç¡®
        if decision and decision.get("recommended_agent") != "é€šç”¨æ™ºèƒ½ä½“":
            recommended_agent = decision.get("recommended_agent")
            valid_agent_ids = []
            
            # æ”¶é›†æ‰€æœ‰æœ‰æ•ˆçš„æ™ºèƒ½ä½“ID
            for agent in a2a_agents:
                agent_id = agent.get("agent_id") or agent.get("agent_ID") or agent.get("agentId", "unknown")
                valid_route_id = f"a2a_{agent_id}"
                valid_agent_ids.append(valid_route_id)
            
            # æ£€æŸ¥æ¨èçš„IDæ˜¯å¦åœ¨æœ‰æ•ˆåˆ—è¡¨ä¸­
            if recommended_agent not in valid_agent_ids:
                logger.error(f"ğŸš« LLMæ¨èäº†æ— æ•ˆçš„æ™ºèƒ½ä½“ID: {recommended_agent}")
                logger.error(f"ğŸ” æœ‰æ•ˆçš„æ™ºèƒ½ä½“IDåˆ—è¡¨: {valid_agent_ids}")
                
                # è®°å½•æ— æ•ˆçš„æ™ºèƒ½ä½“IDä¸ºå¤±è´¥
                if recommended_agent not in failed_agents:
                    failed_agents.append(recommended_agent)
                    state["failed_a2a_agents"] = failed_agents
                
                # å¢åŠ supervisoré‡è¯•è®¡æ•°
                current_retry_count = state.get("supervisor_retry_count", 0) + 1
                state["supervisor_retry_count"] = current_retry_count
                
                # ğŸ”¥ æ”¹è¿›ç­–ç•¥ï¼šä¼˜å…ˆé‡æ–°å†³ç­–ï¼Œåªæœ‰é‡è¯•è¿‡å¤šæ—¶æ‰å¼ºåˆ¶ä½¿ç”¨é€šç”¨æ™ºèƒ½ä½“
                if current_retry_count >= 5:
                    logger.warning(f"ğŸš¨ Supervisorå·²é‡è¯• {current_retry_count} æ¬¡ï¼Œå¼ºåˆ¶ä½¿ç”¨é€šç”¨æ™ºèƒ½ä½“")
                    # å¼ºåˆ¶ä½¿ç”¨é€šç”¨æ™ºèƒ½ä½“
                    original_reasoning = decision.get('reasoning', 'åŸå§‹LLMæ¨è')
                    decision = {
                        "analysis": f"ç»è¿‡å¤šæ¬¡é‡è¯•ä»æ¨èæ— æ•ˆæ™ºèƒ½ä½“ID: {recommended_agent}",
                        "recommended_agent": "é€šç”¨æ™ºèƒ½ä½“",
                        "confidence": 0.8,
                        "reasoning": f"ç»è¿‡ {current_retry_count} æ¬¡é‡è¯•ï¼ŒLLMä»æ¨èæ— æ•ˆçš„æ™ºèƒ½ä½“IDã€‚æœ‰æ•ˆID: {', '.join(valid_agent_ids)}ã€‚ä¸ºé¿å…æ— é™å¾ªç¯ï¼Œå¼ºåˆ¶ä½¿ç”¨é€šç”¨æ™ºèƒ½ä½“ã€‚æœ€åæ¨èç†ç”±ï¼š{original_reasoning}",
                        "fallback": "é€šç”¨æ™ºèƒ½ä½“",
                        "failure_reason": f"é‡è¯•æ¬¡æ•°è¿‡å¤šï¼Œæœ€åæ— æ•ˆID: {recommended_agent}",
                        "retry_count": current_retry_count
                    }
                    state["route_to_a2a"] = None
                    logger.info("ğŸ”„ å·²è®¾ç½®è·¯ç”±åˆ°é€šç”¨æ™ºèƒ½ä½“")
                else:
                    logger.warning(f"ğŸ”„ ç¬¬ {current_retry_count} æ¬¡é‡è¯•ï¼Œè®°å½•æ— æ•ˆIDå¹¶é‡æ–°è¿›è¡Œsupervisorå†³ç­–")
                    
                    # æ·»åŠ é‡è¯•æ¶ˆæ¯ç»™ç”¨æˆ·
                    retry_message = AIMessage(content=f"âš ï¸ æ£€æµ‹åˆ°æ™ºèƒ½ä½“è·¯ç”±é”™è¯¯ï¼ˆç¬¬{current_retry_count}æ¬¡ï¼‰ï¼Œæ­£åœ¨é‡æ–°é€‰æ‹©åˆé€‚çš„æ™ºèƒ½ä½“...")
                    state["messages"].append(retry_message)
                    
                    # ğŸ”¥ å…³é”®ä¿®å¤ï¼šç›´æ¥åœ¨supervisorå†…éƒ¨é‡æ–°è¿›è¡Œå†³ç­–ï¼Œè€Œä¸æ˜¯ä¾èµ–è·¯ç”±
                    logger.info(f"ğŸ”„ å½“å‰é‡è¯•æ¬¡æ•°: {current_retry_count}/5ï¼Œç«‹å³é‡æ–°è¿›è¡Œå†³ç­–")
                    
                    # æ¸…é™¤ä¹‹å‰çš„å†³ç­–ï¼Œé‡æ–°å¼€å§‹å†³ç­–è¿‡ç¨‹
                    state["route_to_a2a"] = None
                    
                    # ğŸ”„ é‡æ–°æ‰§è¡Œå†³ç­–é€»è¾‘ï¼ˆä»ç¬¬4æ­¥å¼€å§‹ï¼‰
                    logger.info("ğŸ”„ é‡æ–°è°ƒç”¨å†³ç­–å¼•æ“...")
                    
                    # é‡æ–°å°è¯•LLMå†³ç­–
                    llm_instance = create_supervisor_llm_instance(state, config)
                    new_decision = None
                    if llm_instance:
                        try:
                            new_decision = await make_llm_decision(state, user_message, llm_instance)
                            logger.info(f"ğŸ”„ é‡æ–°å†³ç­–ç»“æœ: {new_decision}")
                        except Exception as e:
                            logger.error(f"ğŸ”„ é‡æ–°å†³ç­–LLMè°ƒç”¨å¤±è´¥: {str(e)}")
                    
                    # å¦‚æœLLMé‡æ–°å†³ç­–ä¹Ÿå¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤å†³ç­–
                    if not new_decision:
                        logger.info("ğŸ”„ é‡æ–°å†³ç­–ä¹Ÿå¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤é€šç”¨æ™ºèƒ½ä½“å†³ç­–")
                        new_decision = {
                            "analysis": "LLMé‡æ–°å†³ç­–å¤±è´¥",
                            "recommended_agent": "é€šç”¨æ™ºèƒ½ä½“",
                            "confidence": 0.7,
                            "reasoning": "LLMå¤šæ¬¡å†³ç­–å¤±è´¥ï¼Œä½¿ç”¨é€šç”¨æ™ºèƒ½ä½“ç¡®ä¿ä»»åŠ¡èƒ½å¤Ÿå®Œæˆ",
                            "fallback": "é€šç”¨æ™ºèƒ½ä½“"
                        }
                    
                    # æ›´æ–°decisionä¸ºæ–°çš„å†³ç­–ç»“æœï¼Œç»§ç»­åç»­æµç¨‹
                    decision = new_decision
                    logger.info(f"ğŸ”„ é‡æ–°å†³ç­–å®Œæˆï¼Œæ–°æ¨è: {decision.get('recommended_agent')}")
                    
                    # ç»§ç»­æ‰§è¡ŒéªŒè¯é€»è¾‘ï¼ˆè®©å®ƒé‡æ–°æ£€æŸ¥æ–°çš„å†³ç­–ï¼‰
        
        # 6. è®¾ç½®è·¯ç”±çŠ¶æ€
        if decision["recommended_agent"] == "é€šç”¨æ™ºèƒ½ä½“":
            state["route_to_a2a"] = None
            logger.info("è·¯ç”±å†³ç­–: é€šç”¨æ™ºèƒ½ä½“")
        else:
            state["route_to_a2a"] = decision["recommended_agent"]
            logger.info(f"è·¯ç”±å†³ç­–: {decision['recommended_agent']}")
        
        # 7. ğŸ”¥ å¤„ç†å·¥ä½œæµè®¡åˆ’ï¼ˆå¯¹äºå•æ­¥å’Œå¤šæ­¥ä»»åŠ¡éƒ½è¦è®¾ç½®ï¼‰
        workflow_plan = decision.get("workflow_plan")
        if decision.get("workflow_type") == "multi_step":
            if workflow_plan:
                # ğŸ”¥ å…³é”®ä¿®å¤ï¼šç¡®ä¿workflow_planä¸­åŒ…å«workflow_typeå­—æ®µ
                workflow_plan["workflow_type"] = "multi_step"
                state["workflow_plan"] = workflow_plan
                state["current_step_index"] = 0  # é‡ç½®ä¸ºç¬¬ä¸€æ­¥
                logger.info(f"ğŸ”„ åˆå§‹åŒ–å¤šæ­¥éª¤å·¥ä½œæµï¼Œæ€»æ­¥æ•°: {workflow_plan.get('total_steps', 1)}")
        else:
            # ğŸ”¥ æ–°å¢ï¼šä¸ºå•æ­¥ä»»åŠ¡ä¹Ÿåˆ›å»ºworkflow_plan
            if workflow_plan:
                # ä½¿ç”¨LLMæä¾›çš„workflow_planï¼Œç¡®ä¿åŒ…å«workflow_type
                workflow_plan["workflow_type"] = "single_step"
                state["workflow_plan"] = workflow_plan
            else:
                # ä¸ºå•æ­¥ä»»åŠ¡åˆ›å»ºé»˜è®¤çš„workflow_plan
                state["workflow_plan"] = {
                    "workflow_type": "single_step",
                    "total_steps": 1,
                    "current_step": 1,
                    "steps": [{
                        "step_id": 1,
                        "description": decision.get("reasoning", "æ‰§è¡Œå•æ­¥ä»»åŠ¡"),
                        "agent_type": decision.get("recommended_agent", "é€šç”¨æ™ºèƒ½ä½“"),
                        "dependencies": [],
                        "outputs": ["ä»»åŠ¡å®Œæˆç»“æœ"]
                    }]
                }
            state["current_step_index"] = 0
            logger.info(f"ğŸ”„ è®¾ç½®å•æ­¥ä»»åŠ¡å·¥ä½œæµï¼š{decision.get('recommended_agent', 'é€šç”¨æ™ºèƒ½ä½“')}")
        
        # 8. è®°å½•å†³ç­–ä¿¡æ¯
        state["supervisor_decision"] = decision
        
        # 9. æ·»åŠ å†³ç­–è¯´æ˜æ¶ˆæ¯ï¼ˆå¯é€‰ï¼Œç”¨äºè°ƒè¯•ï¼‰
        if logger.isEnabledFor(logging.INFO):
            workflow_info = ""
            if decision.get("workflow_type") == "multi_step":
                workflow_plan = decision.get("workflow_plan", {})
                total_steps = workflow_plan.get("total_steps", 1)
                steps = workflow_plan.get("steps", [])
                
                # ğŸ”¥ æ–°å¢ï¼šæ˜¾ç¤ºå®Œæ•´çš„å·¥ä½œæµæ­¥éª¤è§„åˆ’
                if steps:
                    step_summary = []
                    for i, step in enumerate(steps, 1):
                        agent_type = step.get("agent_type", "æœªçŸ¥æ™ºèƒ½ä½“")
                        description = step.get("description", "æœªçŸ¥ä»»åŠ¡")
                        
                        # ç¾åŒ–æ™ºèƒ½ä½“åç§°æ˜¾ç¤º
                        if agent_type == "é€šç”¨æ™ºèƒ½ä½“":
                            agent_display = "é€šç”¨æ™ºèƒ½ä½“"
                        elif agent_type.startswith("a2a_"):
                            # ä»A2Aæ™ºèƒ½ä½“åˆ—è¡¨ä¸­æ‰¾åˆ°å¯¹åº”çš„ä¸­æ–‡åç§°
                            agent_display = agent_type
                            for agent in state.get("a2a_agents", []):
                                agent_id = agent.get("agent_id") or agent.get("agent_ID") or agent.get("agentId", "")
                                if f"a2a_{agent_id}" == agent_type:
                                    agent_display = agent.get("name", agent_type)
                                    break
                        else:
                            agent_display = agent_type
                        
                        step_summary.append(f"ç¬¬{i}æ­¥: {description} (æ‰§è¡Œè€…: {agent_display})")
                    
                    steps_detail = "\n".join([f"   {step}" for step in step_summary])
                    workflow_info = f"\n\nğŸ“‹ **å¤šæ­¥éª¤å·¥ä½œæµè§„åˆ’** (å…±{total_steps}æ­¥):\n{steps_detail}"
                else:
                    workflow_info = f" (å¤šæ­¥éª¤å·¥ä½œæµ å…±{total_steps}æ­¥)"
            
            decision_msg = f"ğŸ”€ **è·¯ç”±å†³ç­–**: {decision['reasoning']}{workflow_info}"
            state["messages"].append(AIMessage(content=decision_msg))
        
        logger.info("=== Supervisor è·¯ç”±å†³ç­–å®Œæˆ ===")
        return state
        
    except Exception as e:
        logger.error(f"Supervisorå†³ç­–è¿‡ç¨‹å¼‚å¸¸: {str(e)}")
        import traceback
        traceback.print_exc()
        
        # å¼‚å¸¸æƒ…å†µä¸‹é»˜è®¤è·¯ç”±åˆ°é€šç”¨æ™ºèƒ½ä½“
        state["route_to_a2a"] = None
        state["supervisor_decision"] = {
            "analysis": "å†³ç­–è¿‡ç¨‹å‡ºç°å¼‚å¸¸",
            "recommended_agent": "é€šç”¨æ™ºèƒ½ä½“",
            "confidence": 0.5,
            "reasoning": f"å†³ç­–å¼‚å¸¸ï¼Œé»˜è®¤ä½¿ç”¨é€šç”¨æ™ºèƒ½ä½“: {str(e)}",
            "fallback": "é€šç”¨æ™ºèƒ½ä½“"
        }
        return state

def create_supervisor_llm_instance(state: AgentState, config: RunnableConfig) -> Optional[ChatOpenAI]:
    """åˆ›å»ºSupervisorä¸“ç”¨çš„LLMå®ä¾‹"""
    try:
        # è·å–æ¨¡å‹é…ç½® - ä¼˜å…ˆçº§é€»è¾‘ï¼šstate.get("model") > config.get("configurable", {}).get("model_name", llm_config.BASE_LLM)
        model_name = (
            state.get("model") 
            if "model" in state and state.get("model") is not None
            else config.get("configurable", {}).get("model_name", llm_config.BASE_LLM)
        )
        openai_api_key = config.get("configurable", {}).get("model_key", os.getenv("OPENAI_API_KEY"))
        
        if not model_name:
            logger.error("æœªé…ç½®æ¨¡å‹åç§°")
            return None
        
        # åˆ›å»ºLLMå®ä¾‹
        llm_instance = ChatOpenAI(
            base_url=os.getenv("OPENAI_BASE_URL"),
            model=model_name,
            model_kwargs={
                "extra_headers": {
                    "Authorization": f"Bearer {openai_api_key}"
                }
            },
            temperature=0.1  # è®¾ç½®è¾ƒä½çš„æ¸©åº¦ä»¥è·å¾—æ›´ç¡®å®šçš„å†³ç­–
        )
        
        logger.info(f"Supervisor LLMå®ä¾‹åˆ›å»ºæˆåŠŸ: {model_name}")
        return llm_instance
        
    except Exception as e:
        logger.error(f"åˆ›å»ºSupervisor LLMå®ä¾‹å¤±è´¥: {str(e)}")
        return None

async def make_llm_decision(state: AgentState, user_message: str, llm_instance: ChatOpenAI) -> Optional[Dict[str, Any]]:
    """ä½¿ç”¨LLMè¿›è¡Œè·¯ç”±å†³ç­–ï¼ˆå¸¦é‡è¯•æœºåˆ¶ï¼‰"""
    max_retries = 3
    
    for attempt in range(max_retries):
        try:
            # 1. åˆ›å»ºå†³ç­–æç¤ºè¯
            decision_prompt = create_supervisor_decision_prompt(state, user_message)
            
            # 2. è°ƒç”¨LLM
            messages = [HumanMessage(content=decision_prompt)]
            
            logger.info(f"è°ƒç”¨LLMè¿›è¡Œè·¯ç”±å†³ç­–... (å°è¯• {attempt + 1}/{max_retries})")
            response = await llm_instance.ainvoke(messages)
            
            # 3. è§£æå†³ç­–ç»“æœ
            decision = parse_supervisor_decision(response.content)
            
            if decision and decision.get("recommended_agent"):
                logger.info(f"LLMå†³ç­–æˆåŠŸ: {decision['recommended_agent']} (å°è¯• {attempt + 1}/{max_retries})")
                return decision
            else:
                logger.warning(f"LLMå†³ç­–è§£æå¤±è´¥ (å°è¯• {attempt + 1}/{max_retries})")
                if attempt < max_retries - 1:
                    # ç­‰å¾…ä¸€ä¸‹å†é‡è¯•
                    await asyncio.sleep(1)
                    continue
                
        except Exception as e:
            logger.error(f"LLMå†³ç­–è¿‡ç¨‹å¼‚å¸¸ (å°è¯• {attempt + 1}/{max_retries}): {str(e)}")
            if attempt < max_retries - 1:
                # å¯¹äºå¯é‡è¯•çš„é”™è¯¯ï¼Œç­‰å¾…åé‡è¯•
                if any(keyword in str(e).lower() for keyword in ["timeout", "connection", "network", "temporary"]):
                    logger.info(f"æ£€æµ‹åˆ°å¯é‡è¯•é”™è¯¯ï¼Œç­‰å¾…åé‡è¯•...")
                    await asyncio.sleep(2 ** attempt)  # æŒ‡æ•°é€€é¿
                    continue
            
    logger.error(f"LLMå†³ç­–åœ¨ {max_retries} æ¬¡å°è¯•åä»ç„¶å¤±è´¥")
    return None




def should_enable_supervisor_mode(state: AgentState) -> bool:
    """åˆ¤æ–­æ˜¯å¦åº”è¯¥å¯ç”¨Supervisoræ¨¡å¼"""
    # æ£€æŸ¥æ˜¯å¦æœ‰A2Aæ™ºèƒ½ä½“é…ç½®
    a2a_agents = state.get("a2a_agents", [])
    if len(a2a_agents) > 0:
        logger.info(f"æ£€æµ‹åˆ° {len(a2a_agents)} ä¸ªA2Aæ™ºèƒ½ä½“ï¼Œå¯ç”¨Supervisoræ¨¡å¼")
        return True
    
    # æ£€æŸ¥æ˜¯å¦åœ¨è¾“å…¥ä¸­æœ‰A2Aæ™ºèƒ½ä½“
    if "input" in state:
        input_section = state["input"]
        if isinstance(input_section, dict):
            input_a2a = input_section.get("a2a_agents", [])
            if len(input_a2a) > 0:
                logger.info(f"è¾“å…¥ä¸­æ£€æµ‹åˆ° {len(input_a2a)} ä¸ªA2Aæ™ºèƒ½ä½“ï¼Œå¯ç”¨Supervisoræ¨¡å¼")
                # å°†A2Aæ™ºèƒ½ä½“å¤åˆ¶åˆ°ä¸»çŠ¶æ€ä¸­
                state["a2a_agents"] = input_a2a
                return True
    
    # æ£€æŸ¥æ˜¯å¦åœ¨input_dataä¸­æœ‰A2Aæ™ºèƒ½ä½“
    if "input_data" in state:
        input_data = state["input_data"]
        if isinstance(input_data, dict):
            input_data_a2a = input_data.get("a2a_agents", [])
            if len(input_data_a2a) > 0:
                logger.info(f"input_dataä¸­æ£€æµ‹åˆ° {len(input_data_a2a)} ä¸ªA2Aæ™ºèƒ½ä½“ï¼Œå¯ç”¨Supervisoræ¨¡å¼")
                # å°†A2Aæ™ºèƒ½ä½“å¤åˆ¶åˆ°ä¸»çŠ¶æ€ä¸­
                state["a2a_agents"] = input_data_a2a
                return True
    
    logger.info("æœªæ£€æµ‹åˆ°A2Aæ™ºèƒ½ä½“ï¼Œè·³è¿‡Supervisoræ¨¡å¼")
    return False

# ä½¿ç”¨ç¤ºä¾‹å’Œæµ‹è¯•åŠŸèƒ½
if __name__ == "__main__":
    import asyncio
    from langgraph_agent.graph.state import create_initial_state
    
    async def test_supervisor_decision():
        """æµ‹è¯•Supervisorå†³ç­–åŠŸèƒ½"""
        print("=== æµ‹è¯•Supervisorå†³ç­–åŠŸèƒ½ ===")
        
        # åˆ›å»ºæµ‹è¯•çŠ¶æ€
        test_state = create_initial_state({
            "messages": [],
            "a2a_agents": [
                {
                    "agent_id": "data_analyst",
                    "name": "æ•°æ®åˆ†æå¸ˆ",
                    "description": "ä¸“ä¸šçš„æ•°æ®åˆ†æå’Œå¯è§†åŒ–æ™ºèƒ½ä½“"
                },
                {
                    "agent_id": "document_writer",
                    "name": "æ–‡æ¡£åŠ©æ‰‹",
                    "description": "ä¸“ä¸šçš„æ–‡æ¡£ç¼–å†™å’Œæ ¼å¼åŒ–æ™ºèƒ½ä½“"
                }
            ],
            "input": {
                "message": [{"type": "human", "content": "å¸®æˆ‘åˆ†æè¿™ä»½é”€å”®æ•°æ®"}]
            }
        })
        
        # æµ‹è¯•å¯ç”¨æ¡ä»¶
        should_enable = should_enable_supervisor_mode(test_state)
        print(f"æ˜¯å¦å¯ç”¨Supervisoræ¨¡å¼: {should_enable}")
        
        print("Supervisorç»Ÿè®¡ä¿¡æ¯: è§„åˆ™å¼•æ“å·²ç§»é™¤")
    
    # è¿è¡Œæµ‹è¯•
    # asyncio.run(test_supervisor_decision())
    print("Supervisor Agentæ¨¡å—åŠ è½½æˆåŠŸ")


def build_workflow_step_instruction(user_message: str, step_info: dict, execution_results: dict, step_number: int) -> str:
    """
    æ„å»ºå·¥ä½œæµæ­¥éª¤çš„ä»»åŠ¡æŒ‡ä»¤ï¼ŒåŒ…å«å‰é¢æ‰€æœ‰æ­¥éª¤çš„æ‰§è¡Œç»“æœ
    
    Args:
        user_message: åŸå§‹ç”¨æˆ·æ¶ˆæ¯
        step_info: å½“å‰æ­¥éª¤ä¿¡æ¯
        execution_results: å‰é¢æ­¥éª¤çš„æ‰§è¡Œç»“æœ
        step_number: å½“å‰æ­¥éª¤ç¼–å·
        
    Returns:
        str: å®Œæ•´çš„ä»»åŠ¡æŒ‡ä»¤
    """
    step_description = step_info.get("description", "")
    agent_type = step_info.get("agent_type", "é€šç”¨æ™ºèƒ½ä½“")
    
    # æ„å»ºåŸºç¡€æŒ‡ä»¤
    instruction = f"""**å¤šæ­¥éª¤å·¥ä½œæµ - ç¬¬{step_number}æ­¥**

**åŸå§‹ç”¨æˆ·è¯·æ±‚**: {user_message}

**å½“å‰æ­¥éª¤ä»»åŠ¡**: {step_description}

**æ‚¨çš„è§’è‰²**: {agent_type}"""
    
    # ğŸ”¥ ä¿®å¤ï¼šæ˜¾ç¤ºå‰é¢æ‰€æœ‰å·²å®Œæˆæ­¥éª¤çš„ç»“æœï¼Œè€Œä¸æ˜¯åªçœ‹dependencies
    if execution_results:
        instruction += "\n\n**å‰ç½®æ­¥éª¤ç»“æœ**:"
        
        # æŒ‰æ­¥éª¤ç¼–å·æ’åºï¼Œç¡®ä¿é¡ºåºæ­£ç¡®
        sorted_results = []
        for agent_id, result in execution_results.items():
            result_step_id = result.get("step_id", 0)
            # åªåŒ…å«å½“å‰æ­¥éª¤ä¹‹å‰çš„ç»“æœ
            if result_step_id < step_number:
                sorted_results.append((result_step_id, result))
        
        # æŒ‰æ­¥éª¤ç¼–å·æ’åº
        sorted_results.sort(key=lambda x: x[0])
        
        # æ·»åŠ æ‰€æœ‰å‰ç½®æ­¥éª¤çš„ç»“æœ
        for step_id, result in sorted_results:
            agent_name = result.get("agent_name", "å‰é¢çš„æ™ºèƒ½ä½“")
            result_content = result.get("result", "")
            timestamp = result.get("timestamp", "")
            success = result.get("success", False)
            
            status_icon = "âœ…" if success else "âŒ"
            instruction += f"\n\n- {status_icon} **{agent_name}çš„æ‰§è¡Œç»“æœ** (æ­¥éª¤{step_id}):"
            
            # ğŸ”¥ ç¡®ä¿ç»“æœå†…å®¹å®Œæ•´ï¼Œæé«˜é•¿åº¦é™åˆ¶
            if len(result_content) > 2000:
                # ä¿ç•™å‰1500å­—ç¬¦å’Œå300å­—ç¬¦ï¼Œç¡®ä¿å…³é”®ä¿¡æ¯ä¸ä¸¢å¤±
                result_content = result_content[:1500] + "\n...(ä¸­é—´éƒ¨åˆ†çœç•¥)...\n" + result_content[-300:]
            
            instruction += f"\n  ```\n  {result_content}\n  ```"
            if timestamp:
                instruction += f"\n  æ—¶é—´: {timestamp[:19]}"  # åªæ˜¾ç¤ºåˆ°ç§’
        
        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°ä»»ä½•å‰ç½®ç»“æœï¼Œæä¾›è¯´æ˜
        if not sorted_results:
            instruction += "\n\n- â„¹ï¸ **å‰ç½®æ­¥éª¤**: è¿™æ˜¯å·¥ä½œæµçš„ç¬¬ä¸€æ­¥ï¼Œæ²¡æœ‰å‰ç½®æ­¥éª¤ç»“æœã€‚"
    
    # æ·»åŠ æ­¥éª¤è¦æ±‚
    instruction += f"""

**æ‰§è¡Œè¦æ±‚**:
- åŸºäºä¸Šè¿°å‰ç½®ç»“æœï¼ˆå¦‚æœ‰ï¼‰å®Œæˆå½“å‰æ­¥éª¤
- ç¡®ä¿è¾“å‡ºè´¨é‡å’Œä¸“ä¸šæ€§
- ä¸ºåç»­æ­¥éª¤æä¾›æ¸…æ™°çš„ç»“æœæ•°æ®

**æœŸæœ›è¾“å‡º**: {', '.join(step_info.get('outputs', ['ä¸“ä¸šçš„æ‰§è¡Œç»“æœ']))}
"""
    
    return instruction


def create_workflow_completion_message(execution_results: dict, workflow_plan: dict) -> str:
    """
    åˆ›å»ºå·¥ä½œæµå®Œæˆçš„æ€»ç»“æ¶ˆæ¯
    
    Args:
        execution_results: æ‰€æœ‰æ­¥éª¤çš„æ‰§è¡Œç»“æœ
        workflow_plan: å·¥ä½œæµè®¡åˆ’
        
    Returns:
        str: å®Œæˆæ¶ˆæ¯
    """
    total_steps = workflow_plan.get("total_steps", 1)
    steps = workflow_plan.get("steps", [])
    
    message = f"""ğŸ‰ **å¤šæ­¥éª¤å·¥ä½œæµæ‰§è¡Œå®Œæˆ**

**æ€»æ­¥æ•°**: {total_steps}
**å®ŒæˆçŠ¶æ€**: æ‰€æœ‰æ­¥éª¤å·²æˆåŠŸæ‰§è¡Œ

**æ‰§è¡Œå†ç¨‹**:"""
    
    for i, step in enumerate(steps, 1):
        step_desc = step.get("description", f"æ­¥éª¤{i}")
        agent_type = step.get("agent_type", "æ™ºèƒ½ä½“")
        
        # æŸ¥æ‰¾å¯¹åº”çš„æ‰§è¡Œç»“æœ
        step_result = None
        for agent_id, result in execution_results.items():
            result_step_id = result.get("step_id", 1)
            if result_step_id == i or (i == 1 and not result.get("step_id")):
                step_result = result
                break
        
        if step_result:
            success = step_result.get("success", False)
            status_icon = "âœ…" if success else "âŒ"
            agent_name = step_result.get("agent_name", agent_type)
        else:
            status_icon = "â“"
            agent_name = agent_type
        
        message += f"\n{i}. {status_icon} **{step_desc}** (æ‰§è¡Œè€…: {agent_name})"
    
    message += f"""

âœ¨ **ä»»åŠ¡æˆåŠŸå®Œæˆï¼** æ‰€æœ‰{total_steps}ä¸ªæ­¥éª¤å‡å·²æŒ‰ç…§å·¥ä½œæµè®¡åˆ’æ‰§è¡Œå®Œæ¯•ã€‚"""
    
    return message
    
'''